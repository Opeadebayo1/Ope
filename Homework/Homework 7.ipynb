{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "%matplotlib inline\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Twitter API Keys\n",
    "consumer_key = \"JMK1jCxlewvpZm7KuNOKdBOx1\"\n",
    "consumer_secret = \"5BL3WwK5iu7SAioFy8mZbDzJN8AQeyjtPxKRfhlz5xZ7fgP6fQ\"\n",
    "access_token = \"201086971-yqXToCo50DaFkBpJHJfxoZ6yiZDn8FiMb0x657WH\"\n",
    "access_token_secret = \"c5y47MU7xRqWhDWJ03XJyoJBqJnEuDm28K6sboL59D5VM\"\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "# Target User Accounts\n",
    "news_sources = [\"BBCWorld\", \"CBSNews\", \"CNN\", \"FoxNews\", \"NYT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: NYT\n",
      "Compound: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oadeb\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\oadeb\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: NYT\n",
      "Compound: nan\n",
      "\n",
      "User: NYT\n",
      "Compound: nan\n",
      "\n",
      "User: NYT\n",
      "Compound: nan\n",
      "\n",
      "User: NYT\n",
      "Compound: nan\n"
     ]
    }
   ],
   "source": [
    "tweet_data = {\n",
    "    \"tweet_source\": [],\n",
    "    \"tweet_text\": [],\n",
    "    \"tweet_date\": [],\n",
    "    \"tweet_vader_score\": [],\n",
    "    \"tweet_neg_score\": [],\n",
    "    \"tweet_pos_score\": [],\n",
    "    \"tweet_neu_score\": []\n",
    "}\n",
    "\n",
    "# Loop through each user\n",
    "for news_agency in news_sources:\n",
    "\n",
    "    # Loop through 5 pages of tweets (total 100 tweets)\n",
    "    for x in range(5):\n",
    "\n",
    "        # Get all tweets from home feed\n",
    "        public_tweets = api.user_timeline(news_agency, page=x)\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets:\n",
    "\n",
    "            # Run Vader Analysis on each tweet\n",
    "            ps = analyzer.polarity_scores(tweet['text'])\n",
    "            compound = ps[\"compound\"]\n",
    "            pos = ps['pos']\n",
    "            neu = ps['neu']\n",
    "            neg = ps['neg']\n",
    "            # source\n",
    "            # text\n",
    "            # date\n",
    "            #compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "            #pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "           # neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "           # neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "            # Add each value to the appropriate array\n",
    "            tweet_data[\"tweet_source\"].append(tweet[\"user\"][\"name\"])\n",
    "            #tweet_text\n",
    "            tweet_data[\"tweet_text\"].append(tweet[\"text\"])\n",
    "            #tweet_date\n",
    "            tweet_data[\"tweet_date\"].append(tweet[\"created_at\"])\n",
    "            #tweet_vader_score\n",
    "            #tweet_neg_score\n",
    "            #tweet_pos_score\n",
    "            #tweet_neu_score\n",
    "            \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn tweet dictionary into dataframe based on the keys\n",
    "\n",
    "# output tweet dataframe into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the tweet_date column, turn the dates into datetime using pd.to_datetime(date_string)\n",
    "\n",
    "# sort the dataframe by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a scatter plot of sentiment (see solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group the sources by sentiment from teh tweet dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the polarity of each of the news agencies in a bar chart (see solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"@BBC\", \"@CBCNews\", \"@CNN\", \"@FoxNews\", \"@NYT\"\n",
    "# Build the scatter plots for each city types\n",
    "plt.scatter(\"@BBC7l, \n",
    "            urban_avg_fare, \n",
    "            s=10*urban_driver_count, c=\"coral\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"Urban\")\n",
    "\n",
    "plt.scatter(hrs_apart, \n",
    "            suburban_avg_fare, \n",
    "            s=10*suburban_driver_count, c=\"skyblue\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"Suburban\")\n",
    "\n",
    "plt.scatter(rural_ride_count, \n",
    "            rural_avg_fare, \n",
    "            s=10*rural_driver_count, c=\"gold\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"Rural\")\n",
    "\n",
    "plt.scatter(hrs_apart, \n",
    "            suburban_avg_fare, \n",
    "            s=10*suburban_driver_count, c=\"skyblue\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"Suburban\")\n",
    "\n",
    "plt.scatter(hrs_apart, \n",
    "            suburban_avg_fare, \n",
    "            s=10*suburban_driver_count, c=\"skyblue\", \n",
    "            edgecolor=\"black\", linewidths=1, marker=\"o\", \n",
    "            alpha=0.8, label=\"Suburban\")\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(\"Pyber Ride Sharing Data (2016)\")\n",
    "plt.ylabel(\"Average Fare ($)\")\n",
    "plt.xlabel(\"Total Number of Rides (Per City)\")\n",
    "plt.xlim((0,40))\n",
    "plt.grid(True)\n",
    "\n",
    "# Create a legend\n",
    "lgnd = plt.legend(fontsize=\"small\", mode=\"Expanded\", \n",
    "                  numpoints=1, scatterpoints=1, \n",
    "                  loc=\"best\", title=\"City Types\", \n",
    "                  labelspacing=0.5)\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "\n",
    "# Incorporate a text label regarding circle size\n",
    "plt.text(42, 35, \"Note:\\nCircle size correlates with driver count per city.\")\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"analysis/Fig1.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
